---
title: "Short bio"
permalink: /bio/
author_profile: true
redirect_from: 
  - /bio/
  - /bio.html
---

I had the pleasure to work in many cool fields. My master thesis was devoted to the algorithmic side of Network Science, i.e. pattern matching and counting, specifically on the [subgraph isomorphism problem](https://en.wikipedia.org/wiki/Subgraph_isomorphism_problem#:~:text=Subgraph%20isomorphism%20is%20a%20generalization%20of%20the%20graph%20isomorphism%20problem,G%20and%20H%20is%20true.). 

I then decided to give industry a try and was a data scientist for about a year and half. This was an exciting time as Transformers had just made their debut so I had the opportunity to learn and apply these architectures first hand. Their mysterious performance also made me realize where I stood in terms of the [Dunning-Kruger effect](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect) and motivated me to double down on my studies. 

Since 2020 I started my PhD. in Computer Science at the [University of Porto](https://www.up.pt/portal/en/).  The main jist of my thesis centers around inductive priors that capture our empirical knowledge of some phenomena with data-driven models, very much in the line of [Model-based deep learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9934915). Examples span from Markov chains that model the regular ticking of the heart, to the fractal character of pathological phenomena as observed in several Medical Imaging modalities. 

Currently I have set my gaze in self-supervised learning. Everyday I become more convinced that reality can be codified with few parameters. *But how few? At what cost?* 